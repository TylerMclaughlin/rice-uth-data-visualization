---
title: "Workshop on Data Visualization at UTH"
author: "R Tyler McLaughlin - Rice University"
date: "`r format(Sys.Date())`"
runtime: shiny
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Motivation for Data Visualization

Visualizing data is, in my belief, vastly more important than reporting the numerical statistics that describe the data.  Especially to the scientist, statistics are always necessary yet never sufficient.  

The synthetic dataset 'Anscombe's quartet' is a terrific example of why you should visualize (in 2D:  "plot") your data.  In a sense, it shows how statistics fail to reveal phenomena that are extremely obvious.  In this lesson, we will use R for its powerful statistics and plotting libraries.

First, in your R script, let's load necessary packages for plotting and manipulating data:

```{r}
# A hashtag turns text into a comment.
# load ggplot2 and data.table packages with library() 
library("ggplot2")
library("data.table")
source('./code/dataVizUtil/R/functions.R')
```

If you get an error message from running the `source()` function, try clicking in the RStudio menus `Session` `Set Working Directory` > `To Source File Location`.  If you get an error message from running the `library()` commands, try the following to install all necessary packages for this lesson:

```{r,eval=FALSE}
install.packages("ggplot2")
install.packages("data.table")
install.packages("Rbokeh")
```

Import the data set into a data.table:

```{r}
anscombe <- data.table(read.csv('./data/anscombe.csv'))
```
What does this numerical data look like? Use this command to view the "head" of the data.table.

```{r}
head(anscombe)
```


By plotting, you see that we have four, quite different data sets.  
We can plot by running the following **ggplot** command.

```{r}
# aes stands for a e s t h e t i c s.  This is a very important function!
# it tells ggplot what to plot and how to map it 
# to the geom_point() function.
# notice the ~ notation. 
ggplot(anscombe,aes(x = x,y = y) ) + geom_point() + facet_wrap(~set)
```

We can use the "color" argument of aes() to assist visualization of complex data.  Here, it's simply coloring by the number assigned to each data point. This makes it easier to see that each set in the quartet has 11 data points. 

```{r}
# color by the data point's number !     
ggplot(anscombe,aes(x=x,y=y,color=factor(d)) ) + geom_point() + facet_wrap(~set,nrow=2,ncol=2)
```

If you're curious, see what happens if you remove the `geom_point()` or `facet_wrap()` terms.

Ok, we have four data sets that appear quite different qualitatively.  How about their statistics?


Let's manipulate data.tables, using their so-called `[i, j, by]` notation (this is derived from SQL).
"i" refers to operations on rows and "j" refers to operations on columns. "by" means calculate "j" grouping by what follows "by =".  **If you can understand this, learning to use R data.tables for your research will be easy.**

```{r}
# .() means "as data.table"
# Stylistically, R often uses periods instead of spaces for variables and functions.
# Let's define new variables "my.Average.X" and "my.Average.Y"
anscombe[,.(my.Average.X = mean(x),my.Average.Y = mean(y)), by = "set" ]
```

That yielded the mean for x, which is the same for all sets.  The same is also true for the mean for y.  This is *not* a bug!  Four distinct data sets look different yet they are exactly the same **on average**.  
This is part of what is special about Anscombe's quartet. 

How about their standard deviation?

```{r}
# The function 'sd' also does exactly what you'd expect
anscombe[,.(my.SD.X = sd(x),my.SD.Y = sd(y)), by = "set" ]
```

For nicer notation, you can also write:

```{r,eval=FALSE}
anscombe[,.(my.SD.X = sd(x),my.SD.Y = sd(y)), .(set) ]
```

Before we move on to another data set, let's compute the Pearson Product-Moment Correlation Coefficient (Pearson's r):

```{r}
# the function cor()
anscombe[,.(my.XY.correlation = cor(x,y)), .(set) ]
```

For a final statistical description of Anscombe's quartet, let's add a linear fit to our plotted data.  
We do this using a `geom_smooth()` layer.

```{r} 
#  add a linear fit.  "lm"  means "linear model"
ggplot(anscombe,aes(x = x, y = y) ) + geom_point(aes(color = factor(d))) + geom_smooth(method = "lm",color = "black",fullrange=TRUE) +  facet_wrap(~set)
```

Recall, the slope of a linear fit is always proportional to Pearson's R.  The value of the slope can be calculated with the `coef()` and `lm()` functions, and some `[]` notation, which is the syntax for indexing lists.

```{r}
# lm(y ~ x) makes a linear model for y as a function of x.  This is 'simple linear regression.'
# coef() yields a list of the coefficients of a linear model.  [2] refers to the slope, [1] to the intercept.
# use ':=' to add a new column called 'slope.'
anscombe[,slope := coef(lm(y ~ x))[2],.(set)]

```

We compare it to Pearson's R, scaled by the ratio of standard deviations, sd(y)/sd(x)*cor(x,y), with the following:

```{r}
anscombe.slopes <- anscombe[,.(slope, scaled.pearson = sd(y)/sd(x)*cor(x,y) ),.(set)]
anscombe.slopes[, are.they.equal := all.equal(slope,scaled.pearson),.(set)]
unique(anscombe.slopes[,,.(set)])
```

# A Real, Biological Example

This example teaches several tricks for visualizing data that is more complex than Anscombe's quartet. This data set has a broad range of discrete variables (a pairwise contact map in protein sequence space) and associated continous variables.  

The data set was generated with the *Gremlin* tool (http://gremlin.bakerlab.org) to predict 3D protein contacts from sequence data alone.  
First *Gremlin* searches a protein database and collects homologous protein sequences from many organisms and computes a multiple sequence alignment.  
It next uses an information-theoretical algorithm to tabulate how pairs of residues covary across homologs.  
Residues with a strong tendency to co-evolve have a high probability of forming a contact in 3-dimensions.  
Cool, right?  Let's get on to visualizing the contact map starting with importing the data set.

Again, we import data by first reading a file then converting it to the ***data.table*** format.
This time, we're reading a .txt file, so we can use the function 'read.table'

```{r}
dt.grd <- data.table(read.table('./data/gremlinContacts_962-1345.txt',header = TRUE))
head(dt.grd)
```

After a short learning curve, data.tables in R make it *very* easy to manipulate data in numerous kinds
of ways.  Here we are adjusting the numbering scheme of the amino acid residues 
by adding the integer 961 to all residue numbers.
":=" means "adding by reference", and translates roughly to "add *this* new column with *this* definition"
<!-- FIX NAMING, because of the i,j notation-->

```{r}
# fix amino acid numbering
dt.grd[,i := i+961]
dt.grd[,j := j+961]
```

`symmetrize()` is a custom function I built, which adds the mirror image of data along the x = y axis. Functions are called like this:

```{r, warning=TRUE}
dt.grd.sym <- symmetrize(dt.grd)
```

Since this is a custom function, you can see what the function does by examining the code:

```{r}
symmetrize
```

Many of these lines of code are data.table operations.  This is an example of "*data munging*":  that is, reshaping the organization of the data without changing the relationships in the data.
Munging is a routine task in data analysis and data.tables is the best tool I've found for making this more tractable.


Let's try plotting this data with ggplot().

To avoid overplotting, let's filter the data, and plot the first 300 data points.  We are filtering rows, so let's do this in data.table "i".  We don't need to write commas if we are just specifying "i".
```{r}

last.value <- 300
dt.filtered <- dt.grd.sym[1:last.value]
nrow(dt.filtered)
```

```{r}
# Note that in many cases, we can also put the 
# aes() function inside the geom_point()
ggplot(dt.filtered) + geom_point(aes(x = i,y = j,colour = -prob)) 
```

This looks OK, but we can do a lot better. Recall that the figure axes are amino acid numbers. We may want to know the exact residue number, and that is not determinable by eye.  

Let's try another package called "Rbokeh" and plot again.  With the `hover` argument, it can report properties of the data point when you hover over it with your mouse.  The `size` argument changes the size of the data points based on one of its associated values.    

```{r}
# load Rbokeh
library(rbokeh)
# ly_points function is like the geom_point function.
# we now have a "hover" argument that we can use.
ly_points(figure(),i,j,data = dt.filtered,size = 13*prob, hover = list(i,j)) 
```


Try hovering over data points.

The `size`, `hover`, and `color` arguments are great ways of visualizing relatively **high-dimensional data**.

We can color with a **ramp**, aka color gradient, where we generate all the hues between two colors.  

Let's first find out how many data points we have...

```{r}
nrow(dt.filtered)
```

Recall that we already defined a variable with this value, named `last.value`.

It's good programming practice to frequently test that the variables we *think are equal* are *in fact equal*.

```{r}
# check to make sure 'last.value' 
# equals the number of data points, as expected.
#  '==' will always return TRUE or FALSE.  
last.value == nrow(dt.filtered)
```

Next let's make a ramp with `r last.value` colors.

```{r}
ramp <- colorRampPalette(c("red", "blue"))(last.value)
length(ramp)
# show the first 20 points of ramp
head(ramp,20)
```

Great.  Next, we'll color using our ramp.  

We can also use the **pipe** syntax '%>%' from the *magrittr* package to make the code more readable.  This lets us pull the function `figure()` outside of the function `ly_points()` and place it upstream,  
improving readability without damaging the results.

Pipes are useful when we have functions of functions of functions...

```{r}
# illustrates piping and coloring by a ramp.
figure() %>%
  ly_points(i, j, data = dt.filtered,
            color = ramp, size = 13*prob,
            hover = list(i, j)) %>%
      x_range(c(957,1350)) %>%
      y_range(c(1350,957)) %>%
      x_axis(label = "amino acid j") %>%
      y_axis(label = "amino acid i")
```

Above, we included axis labels and also flipped the data along the vertical axis by specifying the `x_range()`. 

After clicking the mouse icon, try zooming in and out of the RBokeh plot with your mouse's scroll wheel.  
Notice how the size of the data points adapts to the extent of the zoom, showcasing one of the many benefits of user interactivity.  Try doing this on a TI-83 Plus. 

colorRampPalette can take multiple colors as arguments.  Try typing

```{r,eval=FALSE}
?colorRampPalette()
```

to learn about the color-perceptual benefits of coloring your data this way.


# Making Highly Interactive Plots

This last section will show you how to make plots that plot different things depending on what you tell it.  A great way of sharing your data with your collaborators who may not know R.  Playing with a shiny app in browser is far easier even if they are familiar with R.

Every shiny app is made with a user interface and and a server file.

Take a standard R plot and wrap it in a `renderPlot()` function.  Wrap an Rbokeh plot in a `renderRbokeh()` function.

The `selectInput()` and `sliderInput()` functions create the drop down menus and the slider input widgets that constitute the user interface and send data to the `renderRbokeh()`.

```{r shiny bokeh}
inputPanel(
  selectInput("color.1", label = "First color:",
              choices = c("red","orange","yellow",
                          "peachpuff","plum"),selected = "red"),
  selectInput("color.2", label = "Second color:",
              choices = c("blue","powderblue","skyblue4",
                          "turquoise2","snow3","steelblue2"),selected = "blue"),
  sliderInput("data.points", label = "Data points for plotting:",
              min = 50, max = 450, step = 25 , value = 300)
)
```
```{r echo=FALSE}
renderRbokeh({dt.plot <- dt.grd.sym[1:input$data.points] 
    # we need to define these again so that 
    # they are updated when the input changes
    n <- nrow(dt.plot)
    ramp <- colorRampPalette(c(input$color.1, input$color.2))(n)
    p <- figure() %>%
      ly_points(i, j, data = dt.plot,
                color = ramp, size = 13*prob,
                hover = list(i, j))
    p %>%
      x_range(c(957,1350)) %>%
      y_range(c(1350,957)) %>%
      x_axis(label = "amino acid j") %>%
      y_axis(label = "amino acid i")
  
  
})
```

To get the figure to respond to the sliders, we also needed to code the following:

```{r eval=FALSE}
renderRbokeh({dt.plot <- dt.grd.sym[1:input$data.points] 
    # we need to define these agin so that 
    # they are updated when the input changes
    n <- nrow(dt.plot)
    ramp <- colorRampPalette(c(input$color.1, input$color.2))(n)
    p <- figure() %>%
      ly_points(i, j, data = dt.plot,
                color = ramp, size = 13*prob,
                hover = list(i, j))
    p %>%
      x_range(c(957,1350)) %>%
      y_range(c(1350,957)) %>%
      x_axis(label = "amino acid j") %>%
      y_axis(label = "amino acid i")
  
  
})
```

The major way in which the plotting code changed from before is that `colorRampPalette()` now takes two *variables*,`input$color.1` and `input$color.2` instead of fixed *strings*.  We are also now filtering the length of the data.table with the parameter `input$data.points`.

# Conclusions

Plotting data is extremely important because descriptive statistics can overlook to many qualities of a dataset.  In the example of Anscombe's quartet, descriptive statistics fail entirely to distinguish data sets.
Data.tables are a great way to manipulate data before plotting or before calculating statistical properties.  They are extremely fast and you can filter data and apply operations by row or by column, using compact `[i,j,by]` notation.

ggplot offers elegance and incredible versatility with simple, modular syntax. Adding layers with `geom` functions and changing aesthetics with the `aes()` command is central to exploratory data analysis.  Facets can be used for easy subplotting.  Rbokeh is another plotting package that in some ways goes beyond ggplot by letting you interact with your data by hovering or zooming.  

The package Shiny lets you create highly interactive plots. 
Shiny plots can be nearly as sophisticated as any other JavaScript apps you will find the internet but are written with much fewer lines of code.  Plus, Shiny is directly compatible with all the data analysis tools provided by R. 

# Questions?  Comments?

Send an email to **rtylermclaughlin@gmail.com**
